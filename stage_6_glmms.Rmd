---
title: "stage_4_bind_mhw_records"
author: "Shahar Chaikin"
date: "2025-09-24"
output: html_document
---

Bind climatologies with records data

Libraries
```{r}
library(tidyverse)
library(glmmTMB)
library(glmm.hp)
```

#Data
```{r}
#data for models
data_models=read_rds("record_data_for_glmms.rds")
#for compatibility with variance partition
data_models_pre_scaled=data_models %>% 
  mutate(
    first_rec_year_sc = scale(first_rec_year)[, 1],
    CPI_sc = scale(CPI)[, 1],
    sources_sc = scale(sources)[, 1],
    annual_c_int_sc = scale(annual_c_int)[, 1],
    year_of_mhws_sc = scale(year_of_mhws)[, 1],
    median_sst_sc = scale(median_sst)[, 1],
    max_s_sst_sc=scale(max_s_sst)[,1])
  
```

#1) Modeling
##GLMM
```{r}
test_main=glmmTMB(
  data = data_models,
  formula = records~
    scale(first_rec_year)+
    scale(CPI)+
    scale(sources)+
    scale(annual_c_int)+
    scale(year_of_mhws)+
    scale(median_sst)+
    scale(max_s_sst)+
    (1|h3_id)+
    (1|species),
  family = "binomial",
  control = glmmTMBControl(optimizer = optim,
                           optArgs = list(method = "BFGS",
                                          maxit = 10000)))
#Colinearity
##median_s_sst
 #            Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
 #   scale(median_sst) 5.90 [5.77, 6.04]         2.43      0.17     [0.17, 0.17]
 # scale(median_s_sst) 6.03 [5.90, 6.18]         2.46      0.17     [0.16, 0.17]

##max_s_sst - no colinearity!

##min_s_sst - no colinearity!

##mean_s_sst
# Moderate Correlation
#               Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
#  scale(median_sst) 5.36 [5.24, 5.48]         2.32      0.19     [0.18, 0.19]
#  scale(mean_s_sst) 5.44 [5.32, 5.57]         2.33      0.18     [0.18, 0.19]

#write_rds(test_main,"test_main.rds")
# test_main=read_rds("glmms\\test_main.rds")
summary(test_main)
performance::check_singularity(test_main)
performance::check_convergence(test_main)
performance::check_overdispersion(test_main)
performance::check_collinearity(test_main)
plot(DHARMa::simulateResiduals(test_main))
MuMIn::r.squaredGLMM(test_main)
#Summarise table for the model
fixed_effects_df <- broom.mixed::tidy(test_main, effects = "fixed") %>%
  # Select and rename columns to match the request
  select(
    Variable = term,
    Coefficient = estimate,
    `Std. Error` = std.error,
    `Z Value` = statistic,
    `P Value` = p.value
  ) %>%
  # Format numeric columns for clean presentation (e.g., 3 decimal places)
  mutate(
    Coefficient = round(Coefficient, 3),
    `Std. Error` = round(`Std. Error`, 3),
    `Z Value` = round(`Z Value`, 2),
    `P Value` = format.pval(`P Value`, digits = 3, eps = 0.0001)
  )
#random effects
random_effects_df <- broom.mixed::tidy(test_main, effects = "ran_pars") 

#write.csv(fixed_effects_df,"fixed_effects_df_binomial.csv",row.names = F)

#Binomial model: AIC = 7687.6
#Betabinomial model: AIC = 7689.6
#Delta is 2 - models are quite similar - I am chossing base on r^2
```

Extract predictions
```{r}
test_main_gg_cint=ggeffects::ggpredict(
  test_main,
  terms=c("annual_c_int [0:183 by =1]"))

test_main_gg_yr=ggeffects::ggpredict(
  test_main,
  terms=c("year_of_mhws [1987:2020 by =1]"))

test_main_gg_sst=ggeffects::ggpredict(
  test_main,
  terms=c("median_sst [14:24 by = 0.5]"))

test_main_gg_s_sst=ggeffects::ggpredict(
  test_main,
  terms=c("max_s_sst [23.7:31.1 by = 0.5]"))

test_main_gg_source=ggeffects::ggpredict(
  test_main,
  terms=c("sources [0:6 by = 0.1]"))

# test_main_gg_source=ggeffects::ggpredict(
#   test_main,
#   terms=c("sources_pred [0.1:2 by = 0.01]"))

test_main_gg_cpi=ggeffects::ggpredict(
  test_main,
  terms=c("CPI [-0.09:0.09 by = 0.001]"))

test_main_gg_yfr=ggeffects::ggpredict(
  test_main,
  terms=c("first_rec_year [1924:2020 by = 1]"))

write_rds(test_main_gg_cint,
          "test_main_gg_cint.rds")
write_rds(test_main_gg_yr,
          "test_main_gg_yr.rds")
write_rds(test_main_gg_sst,
          "test_main_gg_sst.rds")
write_rds(test_main_gg_source,
          "test_main_gg_source.rds")
write_rds(test_main_gg_cpi,
          "test_main_gg_cpi.rds")
write_rds(test_main_gg_yfr,
          "test_main_gg_yfr.rds")
write_rds(test_main_gg_s_sst,
          "test_main_gg_s_sst.rds")
```

####Plot model
```{r}
#c_intensity
test_main_cint_p=ggplot(filtered_data_before_first_record_dt_sst_meff_2020)+
  geom_point(aes(x=annual_c_int,y=records),
             alpha=0.3,
             color="grey")+
  geom_ribbon(data=test_main_gg_cint,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_cint,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="Cumulative intensity (°C-days)",
       y="Record status",
       title="C) MHWs")+
  theme_bw()+
  theme(axis.title.y = element_blank())


#c_intensity zoom
test_main_cint_p_zoom=ggplot(filtered_data_before_first_record_dt_sst_meff_2020)+
  geom_ribbon(data=test_main_gg_cint,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_cint,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="Cumulative intensity (°C-days)",
       y="Record status")+
  theme_bw()+
  theme(axis.title.y = element_blank())+
coord_cartesian(ylim=c(0,.1))+
  scale_y_continuous(breaks = seq(0,0.1,by=0.05))


#embed cint
embeded_cint <- test_main_cint_p +
  annotation_custom(ggplotGrob(test_main_cint_p_zoom),
                    xmin = 50, xmax = 150,
                    ymin = 0.1, ymax = 0.9)


#years
test_main_yr_p=ggplot(filtered_data_before_first_record_dt_sst_meff_2020)+
  geom_point(aes(x=year_of_mhws,y=records),
             alpha=0.3,
             color="grey")+
  geom_ribbon(data=test_main_gg_yr,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_yr,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="Year",
       y="Record status",
       title="A) Time")+
  theme_bw()+
  theme(axis.title.y = element_blank())


#SST
test_main_sst_p=ggplot(filtered_data_before_first_record_dt_sst_meff_2020)+
  geom_point(aes(x=median_sst,y=records),
             alpha=0.3,
             color="grey")+
  geom_ribbon(data=test_main_gg_sst,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_sst,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="SST (°C)",
       y="Record status",
       title="B) SST")+
  theme_bw()+
  theme(axis.title.y = element_blank())

#SST zoom
test_main_sst_p_zoom=ggplot(filtered_data_before_first_record_dt_sst_meff_2020)+
  geom_ribbon(data=test_main_gg_sst,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_sst,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="SST (°C)",
       y="Record status")+
  theme_bw()+
  coord_cartesian(ylim=c(0,.05))+
  scale_y_continuous(breaks = seq(0,0.05,by=0.025))+
  theme(axis.title = element_blank(),
        plot.background = element_rect(fill = "transparent", colour = NA))

#embed sst
embeded_sst <- test_main_sst_p +
  annotation_custom(ggplotGrob(test_main_sst_p_zoom),
                    xmin = 15, xmax = 23,
                    ymin = 0.1, ymax = 0.9)+
  theme(axis.title.y = element_blank())

```

```{r}
test_main_grid=gridExtra::grid.arrange(left="Probability of record occurrence",
  test_main_yr_p,
                        embeded_sst,
                        test_main_cint_p,
                        ncol = 2,
                        nrow=2,
  layout_matrix = rbind(c(1, 1,1,1), # Row 1: P1 and P2
                        c(2,2,3,3)))


ggsave(filename ="test_main_grid.png" ,plot =test_main_grid ,device = "jpeg",units = "cm",width = 20,height = 15)
```

Plot non-focal
```{r}
#Source
test_main_source_p=ggplot(filtered_data_before_first_record_dt_sst_meff)+
  geom_point(aes(x=sources,y=records),
             alpha=0.3,
             color="grey")+
  geom_ribbon(data=test_main_gg_source,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_source,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="Sources",
       y="Record status",
       title="A) Sources")+
  theme_bw()+
  theme(axis.title.y = element_blank())

#CPI
test_main_cpi_p=ggplot(filtered_data_before_first_record_dt_sst_meff)+
  geom_point(aes(x=CPI,y=records),
             alpha=0.3,
             color="grey")+
  geom_ribbon(data=test_main_gg_cpi,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_cpi,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="CPI (m/s)",
       y="Probability of record occurrence",
       title="B) Current Propagation Index")+
  theme_bw()+
  theme(axis.title.y = element_blank())
test_main_cpi_p

#Year of first record
test_main_yfr_p=ggplot(filtered_data_before_first_record_dt_sst_meff)+
  geom_point(aes(x=first_rec_year,y=records),
             alpha=0.3,
             color="grey")+
  geom_ribbon(data=test_main_gg_yfr,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_yfr,
              aes(x=x,y=predicted),
            linewidth=1)+
  labs(x="Year of first record",
       y="Probability of record occurrence",
       title="C) Year of first record")+
  theme_bw()+
  theme(axis.title.y = element_blank())+
    scale_x_continuous(breaks = seq(1920,2020,by=20))
test_main_yfr_p

#YFR zoom
test_main_yfr_p_zoom=ggplot(filtered_data_before_first_record_dt_sst_meff)+
  geom_ribbon(data=test_main_gg_yfr,
              aes(x=x,ymin=conf.low,ymax=conf.high),
              alpha=0.3,
              fill="#E61316")+
  geom_line(data=test_main_gg_yfr,
              aes(x=x,y=predicted),
            linewidth=1)+
  theme_bw()+
  coord_cartesian(ylim=c(0,.08))+
  scale_y_continuous(breaks = seq(0,0.08,by=0.04))+
  scale_x_continuous(breaks = seq(1920,2020,by=20))+
  theme(axis.title = element_blank(),
        plot.background = element_rect(fill = "transparent", colour = NA))

#embed yfr
embeded_yfr <- test_main_yfr_p +
  annotation_custom(ggplotGrob(test_main_yfr_p_zoom),
                    xmin = 1940, xmax = 2000,
                    ymin = 0.1, ymax = 0.9)+
  theme(axis.title.y = element_blank())
```

Non climatic panel
```{r}
test_main_grid_nc=gridExtra::grid.arrange(
  left="Probability of record occurrence",
  test_main_source_p,
  test_main_cpi_p,
  embeded_yfr,
  layout_matrix = rbind(c(1), # Row 1: P1 and P2
                        c(2),
                        c(3)))


ggsave(filename ="test_main_grid_nc.png" ,plot =test_main_grid_nc ,device = "jpeg",units = "cm",width = 15,height = 20)
```

#2) R2 partition
```{r}
####################
#Variance partition#
#####################
#Run Hierarchical Variance Partitioning using glmm.hp
## The glmm.hp function calculates the Marginal R2 (R2m) and then decomposes
## it into the individual contribution of each fixed effect predictor using
## hierarchical partitioning (average shared variance method).
#model
test_main_r_part=glmmTMB(
  data = data_models_pre_scaled,
  formula = records~
    first_rec_year_sc+
    CPI_sc+
    sources_sc+
    annual_c_int_sc+
    year_of_mhws_sc+
    median_sst_sc+
    max_s_sst_sc+
    (1|h3_id)+
    (1|species),
  family = "binomial")

R2_partition_results <-glmm.hp(test_main_r_part,
                                #iv =iv,
                                type="R2") # Specify that I want adjusted R2 partitioning

R2_partition_results
write_rds(R2_partition_results,"R2_partition_results_test_main.rds")

#Interpretation
##Unique - The R2 explained by the predictor alone, i.e., in a model containing only that predictor.

##Average.share - The R2 explained by the predictor jointly with other predictors, calculated as the average improvement in R2 across all possible models where that predictor is added. This is the primary metric for individual predictor importance.

##Individual - The total contribution of the predictor to the model Rm. This is the sum of its Unique contribution and its Average.share contribution: Unique+Average.share.

##I.perc(%)	- The percentage contribution of the predictor to the total Rm. Calculated as:
#Individual/Rm2 ×100%.


############UPDATE
#Save as csv
R2_partition_results_df=R2_partition_results[[2]] %>% 
  as_data_frame() %>% 
  rownames_to_column() %>% 
  rename(predictors=1,
         Unique =2,
         Average.share=3,
         Individual=4,
         `I.perc(%)`=5) %>% 
  mutate(predictors=case_when(predictors%in%"1"~"Year of first record",
                              predictors%in%"2"~"CPI",
                              predictors%in%"3"~"Sources",
                              predictors%in%"4"~"Cumulative intensity",
                              predictors%in%"5"~"Year",
                              predictors%in%"6"~"SST - spatiotemporal",
                              predictors%in%"7"~"SST - spatial")) %>% 
  # 👇 ADD THIS PART TO SUM DOWN THE COLUMNS AND ADD A NEW ROW
  bind_rows(
    summarise(., 
      predictors = "", # Set the predictor name to an empty string (" ")
      across(
        .cols = c(Unique, Average.share, Individual, `I.perc(%)`), # Specify the columns to sum
        .fns = ~sum(., na.rm = TRUE) # Apply the sum function
      )
    )
  )
  
write.csv(R2_partition_results_df,"R2_partition_results_df_test_main.csv",row.names = F)
```


#3) Model selection
Using dredge
```{r}
# Dredge searches all possible combinations of fixed effects.
# It automatically keeps the random effects ((1|h3_id) + (1|species)) in ALL models.

# 1.1 Set MuMIn's options to prevent NA's from failing the model
# This is crucial for dredge()
options(na.action = "na.fail")

# It also generates the null model (intercept only) and the global model (all fixed effects).
cat("\nPerforming Model Dredging (comparing all 64 models)...\n")
model_selection_table <-MuMIn::dredge(
  test_main,
  rank = "AICc" # Use AIC corrected for small sample sizes
)

cleaned_table <- as.data.frame(model_selection_table)

# Identify all columns that are of type 'numeric' or 'integer' to process
numeric_cols <- names(cleaned_table)[
  sapply(cleaned_table, function(x) is.numeric(x))
]

# 2. Apply rounding, convert to character, and replace NAs with NA_character_
# The 'format' function ensures trailing zeros are kept (e.g., 0.1 -> "0.100").
cleaned_table <- cleaned_table %>%
  mutate(across(all_of(numeric_cols), 
                ~ if_else(is.na(.), 
                          NA_character_, # Preserve NA as character for the next step
                          format(round(., 3), nsmall = 3))))

# 3. Use data.table::replace_na() (or just base R if preferred, as data.table's main
# function is replace_na, not just replace) or a similar targeted replacement.
# Since the request was for data.table::, here is a way using data.table syntax
# to perform the final step, although using base R's is.na() on the whole data.frame is cleaner here:

# Convert to data.table temporarily for the final NA replacement step
data.table::setDT(cleaned_table)

# Use data.table's powerful subsetting and replacement for all columns.
# We are replacing the character NAs (NA_character_) with "-"
for (j in 1:ncol(cleaned_table)) {
  data.table::set(cleaned_table, 
                  i = which(is.na(cleaned_table[[j]])), 
                  j = j, 
                  value = "-")
}

# Convert back to data.frame if you prefer
cleaned_table2 <- as.data.frame(cleaned_table) %>% 
  select(-1,-2) %>% 
  rename(`Cumulative intensity`=1,
         CPI=2,
         `Year of first record`=3,
         `SST - spatial`=4,
         `SST - spatiotemporal`=5,
         `Sources`=6,
         `Year`=7) %>% 
  mutate(Model=row_number()) %>%
  relocate(Model) %>% 
  as_tibble()

write.csv(cleaned_table2,"cleaned_table.csv",row.names = F)


simportance_ranking <- MuMIn::sw(model_selection_table)
importance_ranking
sw_df_long <- data.frame(
  Predictor = names(importance_ranking),
  SW = as.numeric(importance_ranking),
  row.names = NULL) %>% 
  mutate(Predictor=case_when(Predictor%in%"cond(scale(sources))"~"Sources",
                             Predictor%in%"cond(scale(year_of_mhws))"~"Year",
                             Predictor%in%"cond(scale(first_rec_year))"~"Year of first record",
                             Predictor%in%"cond(scale(median_sst))"~"SST - spatiotemporal",
                             Predictor%in%"cond(scale(CPI))"~"CPI",
                             Predictor%in%"cond(scale(annual_c_int))"~"Cumulative intensity",
                             Predictor%in%"cond(scale(max_s_sst))"~"SST - spatial"))

write.csv(sw_df_long,"sw_df_long.csv")
# Reset global options
options(na.action = "na.omit")
```